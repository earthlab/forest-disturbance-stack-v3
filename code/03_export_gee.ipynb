{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a1cddf3",
   "metadata": {},
   "source": [
    "# Export the standardized anomalies and hotter drought fingerprint data to local, as well as normal PDSI data & forest mask\n",
    "\n",
    "Run 02_hotter_drought.ipynb first to generate the hotter drought data and export to GEE asset\n",
    "\n",
    "Note that you will need to put an activated Google Service account JSON file in the 'config/secrets/' directory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96cd2a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root found at: C:\\Users\\tymc5571\\dev\\forest-disturbance-stack-v3\n",
      "‚úÖ Directory already exists: C:\\Users\\tymc5571\\dev\\forest-disturbance-stack-v3\\data\\raw\n",
      "‚úÖ Directory already exists: C:\\Users\\tymc5571\\dev\\forest-disturbance-stack-v3\\data\\derived\n",
      "‚úÖ Directory already exists: C:\\Users\\tymc5571\\dev\\forest-disturbance-stack-v3\\config\\secrets\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import time\n",
    "import random\n",
    "import contextlib\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import ee\n",
    "import rioxarray as rxr\n",
    "from rioxarray.merge import merge_arrays\n",
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "\n",
    "from find_set_root import find_set_project_root\n",
    "PROJECT_ROOT = find_set_project_root()\n",
    "print(f\"Project root found at: {PROJECT_ROOT}\")\n",
    "import utils.general_functions as ugf\n",
    "\n",
    "\n",
    "DIR_RAW = os.path.join(PROJECT_ROOT, 'data', 'raw')\n",
    "DIR_DERIVED = os.path.join(PROJECT_ROOT, 'data', 'derived')\n",
    "DIR_SECRETS = os.path.join(PROJECT_ROOT, 'config', 'secrets')\n",
    "ugf.dir_ensure([DIR_RAW, DIR_DERIVED, DIR_SECRETS])\n",
    "\n",
    "#Prepare to use Earth Engine\n",
    "ee.Authenticate()\n",
    "ee.Initialize(project = 'ee-tymc5571-multi-disturbance')\n",
    "\n",
    "\n",
    "\n",
    "############################\n",
    "# USER-SET SERVICE FILE, YEARS, and AOI\n",
    "############################\n",
    "SERVICE_FILE = os.path.join(DIR_SECRETS, 'ee-tymc5571-goodfire-72076a6632b5.json')\n",
    "\n",
    "FIRST_YEAR = 2000\n",
    "LAST_YEAR = 2020\n",
    "\n",
    "states = ee.FeatureCollection('TIGER/2018/States')\n",
    "western_states_names = [\n",
    "    'Washington', 'Oregon', 'California', 'Idaho', 'Nevada', 'Montana',\n",
    "    'Wyoming', 'Utah', 'Colorado', 'Arizona', 'New Mexico'\n",
    "]\n",
    "aoi = states.filter(ee.Filter.inList('NAME', western_states_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32c70ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS\n",
    "\n",
    "def remove_to_bands_append(image):\n",
    "    \"\"\"\n",
    "    Renames bands in the input Earth Engine Image by removing the first part\n",
    "    (before the first underscore) from each band name.\n",
    "\n",
    "    Args:\n",
    "        image (ee.Image): The input image.\n",
    "\n",
    "    Returns:\n",
    "        ee.Image: The image with renamed bands.\n",
    "    \"\"\"\n",
    "    old_names = image.bandNames()\n",
    "    new_names = old_names.map(lambda name: ee.String(name).split('_').slice(1).join('_'))\n",
    "    return image.rename(new_names)\n",
    "\n",
    "def toBands_with_projection(collection):\n",
    "    collection = ee.ImageCollection(collection)\n",
    "    image = collection.toBands()\n",
    "    reference_img = ee.Image(collection.first())\n",
    "    return image.setDefaultProjection(reference_img.projection())\n",
    "\n",
    "# Define the functions to compute annual and summer terraclimate means\n",
    "def annual_terraclimate_image(index, years):\n",
    "\n",
    "    def annual_terraclimate_images(year):\n",
    "        year = ee.Number(year)\n",
    "        mean_image = terraclimate \\\n",
    "            .filter(ee.Filter.calendarRange(year, year, 'year')) \\\n",
    "            .select(index) \\\n",
    "            .mean() \\\n",
    "            .rename(ee.String(index).cat('_annual_').cat(year.format('%d')))\n",
    "        return mean_image\n",
    "\n",
    "    annual_images = years.map(annual_terraclimate_images)\n",
    "    annual_collection = ee.ImageCollection(annual_images)\n",
    "    #annual_image = annual_collection.toBands()\n",
    "    annual_image = toBands_with_projection(annual_collection)\n",
    "    annual_image = remove_to_bands_append(annual_image)\n",
    "    return(annual_image)\n",
    "\n",
    "\n",
    "\n",
    "def _download_file_from_drive(file_id, file_name, temp_dir, service_account_file):\n",
    "    try:\n",
    "        # Authenticate service account\n",
    "        SCOPES = ['https://www.googleapis.com/auth/drive.readonly']\n",
    "        credentials = service_account.Credentials.from_service_account_file(\n",
    "            os.path.abspath(service_account_file), scopes=SCOPES\n",
    "        )\n",
    "        service = build('drive', 'v3', credentials=credentials)\n",
    "\n",
    "        request = service.files().get_media(fileId=file_id)\n",
    "        local_path = os.path.join(temp_dir, file_name)\n",
    "        with open(local_path, 'wb') as f:\n",
    "            downloader = MediaIoBaseDownload(f, request)\n",
    "            done = False\n",
    "            while not done:\n",
    "                status, done = downloader.next_chunk()\n",
    "        time.sleep(random.uniform(0.5, 1.5))  # Random delay\n",
    "        print(f\"‚¨áÔ∏è Downloaded {file_name}\")\n",
    "        return local_path\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error downloading {file_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def download_merge_from_drive(\n",
    "    description: str,\n",
    "    local_filename: str,\n",
    "    drive_folder: str,\n",
    "    service_account_file: str,\n",
    "    compress: str = \"deflate\",\n",
    "    check_existing: bool = True,\n",
    "    n_workers: int = 1\n",
    ") -> str:\n",
    "    local_filename = os.path.abspath(local_filename)\n",
    "    if check_existing and os.path.exists(local_filename):\n",
    "        print(f\"‚úÖ File already exists: {local_filename}\")\n",
    "        return local_filename\n",
    "\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    datasets = []\n",
    "\n",
    "    try:\n",
    "        SCOPES = ['https://www.googleapis.com/auth/drive.readonly']\n",
    "        credentials = service_account.Credentials.from_service_account_file(\n",
    "            os.path.abspath(service_account_file), scopes=SCOPES\n",
    "        )\n",
    "        service = build('drive', 'v3', credentials=credentials)\n",
    "\n",
    "        folder_results = service.files().list(\n",
    "            q=f\"name='{drive_folder}' and mimeType='application/vnd.google-apps.folder' and trashed=false\",\n",
    "            fields=\"files(id, name)\"\n",
    "        ).execute()\n",
    "        folders = folder_results.get('files', [])\n",
    "        if not folders:\n",
    "            raise FileNotFoundError(f\"‚ùå Folder '{drive_folder}' not found or not shared with service account.\")\n",
    "        folder_id = folders[0]['id']\n",
    "\n",
    "        file_results = service.files().list(\n",
    "            q=f\"'{folder_id}' in parents and trashed=false and name contains '{description}' and name contains '.tif'\",\n",
    "            fields=\"files(id, name)\"\n",
    "        ).execute()\n",
    "        files = file_results.get('files', [])\n",
    "        if not files:\n",
    "            raise FileNotFoundError(f\"‚ùå No matching .tif files found for '{description}' in '{drive_folder}'.\")\n",
    "\n",
    "        print(f\"üìÅ Found {len(files)} files. Starting download...\")\n",
    "\n",
    "        downloaded_paths = []\n",
    "        if n_workers == 1:\n",
    "            for file in files:\n",
    "                path = _download_file_from_drive(file['id'], file['name'], temp_dir, service_account_file)\n",
    "                if path:\n",
    "                    downloaded_paths.append(path)\n",
    "        else:\n",
    "            with ThreadPoolExecutor(max_workers=n_workers) as executor:\n",
    "                futures = [\n",
    "                    executor.submit(_download_file_from_drive, file['id'], file['name'], temp_dir, service_account_file)\n",
    "                    for file in files\n",
    "                ]\n",
    "                for future in as_completed(futures):\n",
    "                    result = future.result()\n",
    "                    if result:\n",
    "                        downloaded_paths.append(result)\n",
    "\n",
    "        for f in downloaded_paths:\n",
    "            ds = rxr.open_rasterio(f, masked=True, chunks=True)\n",
    "            datasets.append(ds)\n",
    "\n",
    "        mosaic = merge_arrays(datasets)\n",
    "        mosaic.rio.to_raster(local_filename, compress=compress)\n",
    "        print(f\"‚úÖ Final merged GeoTIFF saved to: {local_filename}\")\n",
    "        return local_filename\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"‚ö†Ô∏è Interrupted by user. Cleaning up and exiting.\")\n",
    "        raise\n",
    "\n",
    "    finally:\n",
    "        for ds in datasets:\n",
    "            with contextlib.suppress(Exception):\n",
    "                ds.close()\n",
    "        try:\n",
    "            shutil.rmtree(temp_dir)\n",
    "            print(f\"üßπ Cleaned up temporary directory: {temp_dir}\")\n",
    "        except Exception as cleanup_err:\n",
    "            print(f\"‚ö†Ô∏è Error during cleanup: {cleanup_err}\")\n",
    "\n",
    "def export_image_to_drive_and_download(\n",
    "    image: ee.Image,\n",
    "    region: ee.Geometry,\n",
    "    description: str,\n",
    "    local_filename: str,\n",
    "    drive_folder: str = \"EarthEngineExports\",\n",
    "    service_account_file: str = \"your-service-account.json\",\n",
    "    scale: int | float = 30,\n",
    "    wait_interval: int = 30,\n",
    "    compress: str = \"deflate\",\n",
    "    check_existing: bool = True,\n",
    "    n_workers: int = 1\n",
    ") -> str:\n",
    "    local_filename = os.path.abspath(local_filename)\n",
    "    if check_existing and os.path.exists(local_filename):\n",
    "        print(f\"‚úÖ File already exists: {local_filename}\")\n",
    "        return local_filename\n",
    "\n",
    "    task = ee.batch.Export.image.toDrive(\n",
    "        image=image.clip(region),\n",
    "        description=description,\n",
    "        folder=drive_folder,\n",
    "        fileNamePrefix=description,\n",
    "        region=region.bounds().getInfo()[\"coordinates\"],\n",
    "        scale=scale,\n",
    "        maxPixels=1e13\n",
    "    )\n",
    "    task.start()\n",
    "    print(f\"üöÄ Started Earth Engine export: {description}\")\n",
    "\n",
    "    while task.active():\n",
    "        print(\"‚è≥ Waiting for Earth Engine export to finish...\")\n",
    "        time.sleep(wait_interval)\n",
    "\n",
    "    status = task.status()\n",
    "    if status[\"state\"] != \"COMPLETED\":\n",
    "        raise RuntimeError(f\"‚ùå Export failed: {status}\")\n",
    "\n",
    "    print(\"‚úÖ Earth Engine export complete. Downloading from Drive...\")\n",
    "\n",
    "    return download_merge_from_drive(\n",
    "        description=description,\n",
    "        local_filename=local_filename,\n",
    "        drive_folder=drive_folder,\n",
    "        service_account_file=service_account_file,\n",
    "        compress=compress,\n",
    "        check_existing=check_existing,\n",
    "        n_workers=n_workers\n",
    "    )\n",
    "\n",
    "def filter_bands_by_year(image: ee.Image, first_year: int, last_year: int) -> ee.Image:\n",
    "    band_names = image.bandNames()\n",
    "\n",
    "    # Create list of allowed years as strings\n",
    "    allowed_years = ee.List.sequence(first_year, last_year).map(\n",
    "        lambda y: ee.Number(y).format('%04d')\n",
    "    )\n",
    "\n",
    "    # Map over band names and keep only those that match an allowed year suffix\n",
    "    def keep_if_valid(band):\n",
    "        band_str = ee.String(band)\n",
    "        year_suffix = band_str.slice(-4)\n",
    "        return ee.Algorithms.If(\n",
    "            allowed_years.contains(year_suffix),\n",
    "            band_str,\n",
    "            None\n",
    "        )\n",
    "\n",
    "    # Map and filter out None\n",
    "    valid_bands = band_names.map(keep_if_valid).removeAll([None])\n",
    "\n",
    "    return image.select(valid_bands)\n",
    "\n",
    "\n",
    "def reclassify_image_binary(value):\n",
    "    def _reclassify(img):\n",
    "        binary_img = img.eq(value).selfMask()\n",
    "        return binary_img.copyProperties(img, ['system:time_start'])\n",
    "    return _reclassify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bdac4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lcms = ee.ImageCollection(\"USFS/GTAC/LCMS/v2024-10\")\n",
    "lcmap = ee.ImageCollection(\"projects/sat-io/open-datasets/LCMAP/LCPRI\")\n",
    "\n",
    "# Inclusive forest mask\n",
    "lcmap_cover = lcmap.filterDate(str(FIRST_YEAR - 1), str(LAST_YEAR))\n",
    "lcms_cover = lcms.filter(ee.Filter.eq('study_area', 'CONUS')).filterDate(str(FIRST_YEAR - 1), str(LAST_YEAR)).select('Land_Cover')\n",
    "\n",
    "lcmap_for = lcmap_cover.map(reclassify_image_binary(4))\n",
    "lcms_for = lcms_cover.map(reclassify_image_binary(1))\n",
    "\n",
    "combined_forest_mask = lcmap_for.map(lambda img: img.reduce(ee.Reducer.max()).gt(0)).max().Or(\n",
    "    lcms_for.map(lambda img: img.reduce(ee.Reducer.max()).gt(0)).max()\n",
    ")\n",
    "combined_forest_mask = combined_forest_mask.setDefaultProjection(lcmap_cover.first().projection())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55a1aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hd_fingerprint_yr_2000', 'hd_fingerprint_yr_2001', 'hd_fingerprint_yr_2002', 'hd_fingerprint_yr_2003', 'hd_fingerprint_yr_2004', 'hd_fingerprint_yr_2005', 'hd_fingerprint_yr_2006', 'hd_fingerprint_yr_2007', 'hd_fingerprint_yr_2008', 'hd_fingerprint_yr_2009', 'hd_fingerprint_yr_2010', 'hd_fingerprint_yr_2011', 'hd_fingerprint_yr_2012', 'hd_fingerprint_yr_2013', 'hd_fingerprint_yr_2014', 'hd_fingerprint_yr_2015', 'hd_fingerprint_yr_2016', 'hd_fingerprint_yr_2017', 'hd_fingerprint_yr_2018', 'hd_fingerprint_yr_2019', 'hd_fingerprint_yr_2020']\n",
      "['pdsi_annual_2000', 'pdsi_annual_2001', 'pdsi_annual_2002', 'pdsi_annual_2003', 'pdsi_annual_2004', 'pdsi_annual_2005', 'pdsi_annual_2006', 'pdsi_annual_2007', 'pdsi_annual_2008', 'pdsi_annual_2009', 'pdsi_annual_2010', 'pdsi_annual_2011', 'pdsi_annual_2012', 'pdsi_annual_2013', 'pdsi_annual_2014', 'pdsi_annual_2015', 'pdsi_annual_2016', 'pdsi_annual_2017', 'pdsi_annual_2018', 'pdsi_annual_2019', 'pdsi_annual_2020']\n"
     ]
    }
   ],
   "source": [
    "#Prep drought\n",
    "\n",
    "hd_fingerprint = ee.Image(\"projects/ee-tymc5571-multi-disturbance/assets/hd_warm_fingerprint\")\n",
    "terraclimate = ee.ImageCollection(\"IDAHO_EPSCOR/TERRACLIMATE\")\n",
    "\n",
    "\n",
    "pdsi_annual = annual_terraclimate_image('pdsi', ee.List.sequence(FIRST_YEAR, LAST_YEAR))\n",
    "\n",
    "hd_fingerprint = filter_bands_by_year(hd_fingerprint, FIRST_YEAR, LAST_YEAR)\n",
    "\n",
    "print(hd_fingerprint.bandNames().getInfo())\n",
    "print(pdsi_annual.bandNames().getInfo())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc69cc8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Started Earth Engine export: pdsi_annual_test\n",
      "‚è≥ Waiting for Earth Engine export to finish...\n",
      "‚è≥ Waiting for Earth Engine export to finish...\n",
      "‚è≥ Waiting for Earth Engine export to finish...\n",
      "‚è≥ Waiting for Earth Engine export to finish...\n",
      "‚úÖ Earth Engine export complete. Downloading from Drive...\n",
      "üìÅ Found 2 files. Starting download...\n",
      "‚¨áÔ∏è Downloaded pdsi_annual_test.tif\n",
      "‚¨áÔ∏è Downloaded pdsi_annual_test.tif\n",
      "‚úÖ Final merged GeoTIFF saved to: C:\\Users\\tymc5571\\dev\\forest-disturbance-stack-v3\\data\\derived\\pdsi_annual.tif\n",
      "üßπ Cleaned up temporary directory: C:\\Users\\tymc5571\\AppData\\Local\\Temp\\tmp93f3p6jo\n",
      "üöÄ Started Earth Engine export: hd_fingerprint\n",
      "‚è≥ Waiting for Earth Engine export to finish...\n",
      "‚è≥ Waiting for Earth Engine export to finish...\n",
      "‚è≥ Waiting for Earth Engine export to finish...\n",
      "‚úÖ Earth Engine export complete. Downloading from Drive...\n",
      "üìÅ Found 2 files. Starting download...\n",
      "‚¨áÔ∏è Downloaded hd_fingerprint.tif\n",
      "‚¨áÔ∏è Downloaded hd_fingerprint.tif\n",
      "‚úÖ Final merged GeoTIFF saved to: C:\\Users\\tymc5571\\dev\\forest-disturbance-stack-v3\\data\\derived\\hd_fingerprint.tif\n",
      "üßπ Cleaned up temporary directory: C:\\Users\\tymc5571\\AppData\\Local\\Temp\\tmpr5a935qv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tymc5571\\AppData\\Local\\miniconda3\\envs\\macrosystems\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3336: SerializationWarning: saving variable None with floating point data as an integer dtype without any _FillValue to use for NaNs\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\tymc5571\\\\dev\\\\forest-disturbance-stack-v3\\\\data\\\\derived\\\\hd_fingerprint.tif'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_image_to_drive_and_download(\n",
    "    image=pdsi_annual,\n",
    "    region=aoi,\n",
    "    description='pdsi_annual_test',\n",
    "    local_filename=os.path.join(DIR_DERIVED, \"pdsi_annual.tif\"),\n",
    "    drive_folder=\"EarthEngineExports\",\n",
    "    service_account_file=SERVICE_FILE,\n",
    "    scale=4638.3,\n",
    "    wait_interval=30,\n",
    "    compress=\"deflate\",\n",
    "    check_existing= True,\n",
    "    n_workers=4\n",
    ")\n",
    "\n",
    "export_image_to_drive_and_download(\n",
    "    image=hd_fingerprint,\n",
    "    region=aoi,\n",
    "    description='hd_fingerprint',\n",
    "    local_filename=os.path.join(DIR_DERIVED, \"hd_fingerprint.tif\"),\n",
    "    drive_folder=\"EarthEngineExports\",\n",
    "    service_account_file=SERVICE_FILE,\n",
    "    scale=4638.3,\n",
    "    wait_interval=30,\n",
    "    compress=\"deflate\",\n",
    "    check_existing= True,\n",
    "    n_workers=4\n",
    ")\n",
    "\n",
    "export_image_to_drive_and_download(\n",
    "    image=combined_forest_mask,\n",
    "    region=aoi,\n",
    "    description='relaxed_forest_mask',\n",
    "    local_filename=os.path.join(DIR_DERIVED, \"relaxed_forest_mask.tif\"),\n",
    "    drive_folder=\"EarthEngineExports\",\n",
    "    service_account_file=SERVICE_FILE,\n",
    "    scale=30,\n",
    "    wait_interval=30,\n",
    "    compress=\"deflate\",\n",
    "    check_existing= True,\n",
    "    n_workers=4\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "macrosystems",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
